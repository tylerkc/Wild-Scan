{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66dc09c8-4c65-48d5-9d8f-a2c0b450ecbb",
   "metadata": {},
   "source": [
    "# (04-d) CUSTOM MODEL (with NO Temporal Features, Margin Loss) EVALUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "11164932-ea09-440b-bbbe-692cc504bdce",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:51:22.057489Z",
     "iopub.status.busy": "2025-07-17T09:51:22.057240Z",
     "iopub.status.idle": "2025-07-17T09:51:22.060906Z",
     "shell.execute_reply": "2025-07-17T09:51:22.060413Z",
     "shell.execute_reply.started": "2025-07-17T09:51:22.057469Z"
    }
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Specify the path to the folder containing your module\n",
    "repo_root = '../'\n",
    "\n",
    "src_path = os.path.join(repo_root, 'src')\n",
    "# Add src_path to sys.path if not already present\n",
    "if src_path not in sys.path:\n",
    "    sys.path.insert(0, src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6162824c-8209-4637-abe6-60e678089805",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:51:27.667296Z",
     "iopub.status.busy": "2025-07-17T09:51:27.666971Z",
     "iopub.status.idle": "2025-07-17T09:51:30.698927Z",
     "shell.execute_reply": "2025-07-17T09:51:30.698408Z",
     "shell.execute_reply.started": "2025-07-17T09:51:27.667274Z"
    }
   },
   "outputs": [],
   "source": [
    "from custom_models import AnimalTemporalClassifier\n",
    "from custom_models import AnimalClassifier\n",
    "from custom_datasets import S3ImageWithTimeFeatureDataset\n",
    "import torch\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1178c0b8-db1b-4db1-ad3e-e6e355858d2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:51:30.700396Z",
     "iopub.status.busy": "2025-07-17T09:51:30.699907Z",
     "iopub.status.idle": "2025-07-17T09:51:30.703109Z",
     "shell.execute_reply": "2025-07-17T09:51:30.702588Z",
     "shell.execute_reply.started": "2025-07-17T09:51:30.700363Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1fdfb7c6-9462-405a-a898-677b70bb5698",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:51:30.703973Z",
     "iopub.status.busy": "2025-07-17T09:51:30.703785Z",
     "iopub.status.idle": "2025-07-17T09:51:31.246061Z",
     "shell.execute_reply": "2025-07-17T09:51:31.245479Z",
     "shell.execute_reply.started": "2025-07-17T09:51:30.703957Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65a24da7-6dcb-4e1a-ab01-d2654e5463d1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:51:35.681992Z",
     "iopub.status.busy": "2025-07-17T09:51:35.681252Z",
     "iopub.status.idle": "2025-07-17T09:51:35.693774Z",
     "shell.execute_reply": "2025-07-17T09:51:35.693248Z",
     "shell.execute_reply.started": "2025-07-17T09:51:35.681962Z"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import tarfile\n",
    "from io import BytesIO\n",
    "import json\n",
    "\n",
    "def download_and_extract_files_from_s3(bucket, key, files_to_extract):\n",
    "    s3 = boto3.client('s3')\n",
    "    obj = s3.get_object(Bucket=bucket, Key=key)\n",
    "    buffer = BytesIO(obj['Body'].read())\n",
    "\n",
    "    extracted_files = {}\n",
    "    with tarfile.open(fileobj=buffer, mode='r:gz') as tar:\n",
    "        for member in tar.getmembers():\n",
    "            if member.name in files_to_extract:\n",
    "                f = tar.extractfile(member)\n",
    "                if f:\n",
    "                    # For JSON, decode as text; for .pth, keep as bytes\n",
    "                    if member.name.endswith('.json'):\n",
    "                        extracted_files[member.name] = f.read().decode('utf-8')\n",
    "                    else:\n",
    "                        extracted_files[member.name] = f.read()\n",
    "    return extracted_files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a4e61a40-666f-4a62-8024-32815f9ff425",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:52:34.042775Z",
     "iopub.status.busy": "2025-07-17T09:52:34.042233Z",
     "iopub.status.idle": "2025-07-17T09:52:35.767471Z",
     "shell.execute_reply": "2025-07-17T09:52:35.766876Z",
     "shell.execute_reply.started": "2025-07-17T09:52:34.042742Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JSON file not found\n",
      ".pth file size: 44813397 bytes\n"
     ]
    }
   ],
   "source": [
    "# Usage example\n",
    "bucket = 'aai-590-tmp2'\n",
    "key ='Resnet18_with_No_Temporal_Margin_Loss/output/pytorch-training-2025-07-17-09-22-39-143/output/model.tar.gz'\n",
    "files_to_extract = ['label2idx.json', 'model.pth']\n",
    "#files_to_extract = ['model.pth']\n",
    "                    \n",
    "extracted_files = download_and_extract_files_from_s3(bucket, key, files_to_extract)\n",
    "\n",
    "# Parse JSON to count classes\n",
    "json_content = extracted_files.get(files_to_extract[0])\n",
    "if json_content:\n",
    "    json_data = json.loads(json_content)\n",
    "    #num_classes = len(json_data.get('classes', []))\n",
    "    num_classes = len(json_data)\n",
    "    print(f'Number of classes: {num_classes}')\n",
    "else:\n",
    "    print('JSON file not found')\n",
    "\n",
    "# The .pth file content is binary, ready for torch.load\n",
    "pth_content = extracted_files.get(files_to_extract[1])\n",
    "if pth_content:\n",
    "    print(f'.pth file size: {len(pth_content)} bytes')\n",
    "    # Example: load with torch.load(BytesIO(pth_content))\n",
    "else:\n",
    "    print('.pth file not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20624e36-f9fc-4f99-ba40-4ecdf0592a66",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:52:57.861921Z",
     "iopub.status.busy": "2025-07-17T09:52:57.861579Z",
     "iopub.status.idle": "2025-07-17T09:52:58.044388Z",
     "shell.execute_reply": "2025-07-17T09:52:58.043831Z",
     "shell.execute_reply.started": "2025-07-17T09:52:57.861899Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bucket_name = \"aai-590-tmp2\"\n",
    "train_val_dir = \"data_split/train_val\"\n",
    "s3_label2idx = f's3://{bucket_name}/{train_val_dir}/label_mapping.json'\n",
    "label2idx = pd.read_json(s3_label2idx, typ='series').to_dict()\n",
    "num_classes = len(label2idx)\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "43c042bd-63bd-498e-9010-b96e566ffb98",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:53:12.931109Z",
     "iopub.status.busy": "2025-07-17T09:53:12.930776Z",
     "iopub.status.idle": "2025-07-17T09:53:13.244132Z",
     "shell.execute_reply": "2025-07-17T09:53:13.243554Z",
     "shell.execute_reply.started": "2025-07-17T09:53:12.931088Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.12/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# initialize custom model with same number of classes based on json file\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = []\n",
    "model = AnimalClassifier(num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b467b0c-b227-4a7c-b489-7365b8b1a021",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:53:15.157126Z",
     "iopub.status.busy": "2025-07-17T09:53:15.156796Z",
     "iopub.status.idle": "2025-07-17T09:53:15.209456Z",
     "shell.execute_reply": "2025-07-17T09:53:15.208890Z",
     "shell.execute_reply.started": "2025-07-17T09:53:15.157104Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AnimalClassifier(\n",
       "  (cnn): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=17, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the weights from the .pth file (from BytesIO or file)\n",
    "model.load_state_dict(torch.load(BytesIO(pth_content), map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ab23973-25df-4fb8-b05e-c49bc04ba46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchviz torchview graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a27ec26-36fa-426b-90f0-b642cab221fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a8b4e7c-ae3a-4f60-90ef-b320b43f68a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchview import draw_graph\n",
    "\n",
    "# Specify input sizes as a tuple of shapes\n",
    "input_sizes = (1, 3, 224, 224)\n",
    "\n",
    "model_graph = draw_graph(\n",
    "    model,\n",
    "    input_size=input_sizes,\n",
    "    expand_nested=True\n",
    ")\n",
    "\n",
    "model_graph.visual_graph.render(filename='custom_model_noTimeVector_architecture')\n",
    "\n",
    "\n",
    "#from IPython.display import Image, display\n",
    "#display(Image(filename='custom_model_noTimeVector_architecture.pdf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d86fe21-dc97-4101-bcd4-fc5decdf0ada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "\n",
    "# Replace 'yourfile.pdf' with your actual file path\n",
    "IFrame('custom_model_noTimeVector_architecture.pdf', width=600, height=400)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0b98e27-1702-4e53-a70a-d829a81f5fbe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:53:36.045033Z",
     "iopub.status.busy": "2025-07-17T09:53:36.044455Z",
     "iopub.status.idle": "2025-07-17T09:53:36.049232Z",
     "shell.execute_reply": "2025-07-17T09:53:36.048716Z",
     "shell.execute_reply.started": "2025-07-17T09:53:36.045008Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'car',\n",
       " 1: 'coyote',\n",
       " 2: 'deer',\n",
       " 3: 'bobcat',\n",
       " 4: 'dog',\n",
       " 5: 'skunk',\n",
       " 6: 'empty',\n",
       " 7: 'cat',\n",
       " 8: 'opossum',\n",
       " 9: 'squirrel',\n",
       " 10: 'raccoon',\n",
       " 11: 'rodent',\n",
       " 12: 'rabbit',\n",
       " 13: 'bird',\n",
       " 14: 'badger',\n",
       " 15: 'fox',\n",
       " 16: 'lizard'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2label = {int(v): k for k, v in label2idx.items()}\n",
    "idx2label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8b8e0c6e-f07e-4d04-a6ce-318c92c58713",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:57:31.425973Z",
     "iopub.status.busy": "2025-07-17T09:57:31.425648Z",
     "iopub.status.idle": "2025-07-17T09:57:31.429393Z",
     "shell.execute_reply": "2025-07-17T09:57:31.428814Z",
     "shell.execute_reply.started": "2025-07-17T09:57:31.425952Z"
    }
   },
   "outputs": [],
   "source": [
    "# Configure s3 locations for evaluation\n",
    "bucket_name = bucket\n",
    "s3_newdata_dir = f's3://{bucket_name}/data_split/train_val/validation2'\n",
    "s3_newdata_csv = f's3://{bucket_name}/data_split/train_val/validation2/val-meta.csv' # used only to extract annotations later\n",
    "s3_newdata_manifest = f's3://{bucket_name}/data_split/train_val/validation2/val-meta.manifest' # should have been generated from datapreprocessing pipeline\n",
    "s3_label_map_uri = f\"s3://{bucket_name}/data_split/train_val/label_mapping.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10b12174-eeea-4454-a946-ddedbb292160",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T09:59:19.145479Z",
     "iopub.status.busy": "2025-07-17T09:59:19.145157Z",
     "iopub.status.idle": "2025-07-17T09:59:19.254599Z",
     "shell.execute_reply": "2025-07-17T09:59:19.253996Z",
     "shell.execute_reply.started": "2025-07-17T09:59:19.145458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEBUG INFO: No Label Encoding needed for this dataset\n",
      "Number of images: 6833\n",
      "Number of batches: 54\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on validation set\n",
    "s3_newdata_set =  's3://aai-590-tmp2/data_split/train_val/validation2/val-meta.csv'\n",
    "\n",
    "new_dataset = []\n",
    "new_dataset = S3ImageWithTimeFeatureDataset(s3_newdata_csv)\n",
    "print(f\"Number of images: {len(new_dataset)}\")\n",
    "\n",
    "new_dataset_loader = []\n",
    "new_dataset_loader = DataLoader(new_dataset, batch_size=128, shuffle=False, num_workers=0)\n",
    "print(f\"Number of batches: {len(new_dataset_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8d387c0a-135e-43eb-ac66-b130f51b4984",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:01:22.252767Z",
     "iopub.status.busy": "2025-07-17T10:01:22.252437Z",
     "iopub.status.idle": "2025-07-17T10:11:39.913242Z",
     "shell.execute_reply": "2025-07-17T10:11:39.912625Z",
     "shell.execute_reply.started": "2025-07-17T10:01:22.252745Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 0 of 54\n",
      "Elapsed time: 9.4315 seconds\n",
      "batch: 20 of 54\n",
      "Elapsed time: 231.0758 seconds\n",
      "batch: 40 of 54\n",
      "Elapsed time: 234.3784 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "pred_labels = []\n",
    "pred_probs = []\n",
    "batch_id = 0\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "with torch.no_grad():\n",
    "    #for image:\n",
    "    #for batch_id in range(len(new_dataset_loader)):\n",
    "    for images_batch, features_batch, scalars_batch in new_dataset_loader:\n",
    "        images, features = images_batch.to(device), features_batch.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        pred_labels_batch = [idx2label[int(idx)] for idx in predicted]\n",
    "\n",
    "        if (batch_id%20 == 0): \n",
    "            end_time = time.time()\n",
    "            elapsed_time = end_time - start_time\n",
    "            print(f\"batch: {batch_id} of {len(new_dataset_loader)}\")\n",
    "            #print(f\"outputs: {outputs}\")\n",
    "            #print(f\"pred_label: {pred_labels_batch}\")\n",
    "            print(f\"Elapsed time: {elapsed_time:.4f} seconds\")\n",
    "            start_time = time.time()\n",
    "\n",
    "        batch_id += 1\n",
    "        pred_labels.extend(pred_labels_batch)\n",
    "        pred_probs.extend(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "52ac7881-a769-4e14-8413-87e80b69712d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:12:29.195625Z",
     "iopub.status.busy": "2025-07-17T10:12:29.195392Z",
     "iopub.status.idle": "2025-07-17T10:12:29.200167Z",
     "shell.execute_reply": "2025-07-17T10:12:29.199649Z",
     "shell.execute_reply.started": "2025-07-17T10:12:29.195606Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-2.2092, -3.4855, -4.0129, -2.7377,  0.9568, -2.2611, -2.3972, -2.0869,\n",
       "        12.7367, -3.0021, -1.0022, -2.8003, -3.0363, -3.0994, -1.8258, -4.1770,\n",
       "        -4.2084])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_probs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "68a44e38-e3b2-4284-81e2-30a006ebb6f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:13:53.639171Z",
     "iopub.status.busy": "2025-07-17T10:13:53.638841Z",
     "iopub.status.idle": "2025-07-17T10:13:53.647990Z",
     "shell.execute_reply": "2025-07-17T10:13:53.647461Z",
     "shell.execute_reply.started": "2025-07-17T10:13:53.639149Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# output: tensor from your model (after ReLU Linear)\n",
    "pred_probs_linear = torch.stack(pred_probs)\n",
    "pred_probs_softmax = F.softmax(pred_probs_linear, dim=1)  # dim=1 for batch x classes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04e7198c-c49f-44da-befe-73df282a8836",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-17T10:19:22.481755Z",
     "iopub.status.busy": "2025-07-17T10:19:22.481415Z",
     "iopub.status.idle": "2025-07-17T10:19:22.599394Z",
     "shell.execute_reply": "2025-07-17T10:19:22.598878Z",
     "shell.execute_reply.started": "2025-07-17T10:19:22.481734Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "pred_probs_df = pred_probs_softmax.numpy()\n",
    "pred_probs_df = pd.DataFrame(pred_probs_df, columns = label2idx.keys())\n",
    "pred_probs_df.to_csv('pred_proba_no_time_margin_loss.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2787a162-d57a-4ff2-8443-ce370528e3b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = f'custom_loss_results/'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "file_name = 'pred_labels.txt'\n",
    "file_path = os.path.join(results_dir, file_name)\n",
    "with open(file_path, 'w') as f:\n",
    "    for item in pred_labels:\n",
    "        f.write(f\"{item}\\n\")\n",
    "\n",
    "file_name = 'pred_probs.txt'\n",
    "file_path = os.path.join(results_dir, file_name)\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    for item in pred_probs:\n",
    "        f.write(f\"{item}\\n\")\n",
    "\n",
    "file_name = 'pred_probs_softmax.txt'\n",
    "file_path = os.path.join(results_dir, file_name)\n",
    "\n",
    "with open(file_path, 'w') as f:\n",
    "    for item in pred_probs_softmax:\n",
    "        f.write(f\"{item}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40c8ef1c-bc44-4ae7-b2a2-2cd7d35bb29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data_csv = pd.read_csv(s3_newdata_set)\n",
    "true_labels = new_data_csv['label'].tolist()\n",
    "\n",
    "restricted_indices = new_data_csv.index[new_data_csv['label'].isin(list(json_data.keys()))].tolist()\n",
    "restricted_true_labels = [true_labels[i] for i in restricted_indices]\n",
    "restricted_pred_labels = [pred_labels[i] for i in restricted_indices]\n",
    "\n",
    "class_report = classification_report(restricted_true_labels, restricted_pred_labels)\n",
    "print(class_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d735585-9101-425e-a9ca-7ddde293606e",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_restricted = accuracy_score(restricted_true_labels, restricted_pred_labels)\n",
    "f1_score_restricted = f1_score(restricted_true_labels, restricted_pred_labels, average='weighted')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448b0cfe-1910-4e13-aad3-44ec56d6ee3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# output: tensor from your model (after ReLU Linear)\n",
    "pred_probs_linear = torch.stack(pred_probs)\n",
    "pred_probs_softmax = F.softmax(pred_probs_linear, dim=1)  # dim=1 for batch x classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d856da9d-34cf-49f0-953f-bdeb11906c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOVELTY RATIO\n",
    "\n",
    "threshold = 0.7  # Example threshold for MSP\n",
    "is_novel = (pred_probs_softmax.max(dim=1)[0] < threshold).sum()\n",
    "novelty_ratio = is_novel/len(pred_probs_softmax)\n",
    "novelty_ratio = novelty_ratio.item()\n",
    "novelty_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed3a1cc-7098-4691-8855-707037f335dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d881b59-d978-48c8-822c-ad33d85a6905",
   "metadata": {},
   "outputs": [],
   "source": [
    "report_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d30e52c-49d4-4200-a6e9-b5b2a800a78f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name = 'multiclass_metrics.json'\n",
    "file_path = os.path.join(results_dir, file_name)\n",
    "\n",
    "report_dict = {\n",
    "    \"multiclass_classification_metrics\": {\n",
    "        \"accuracy\": {\"value\": accuracy_restricted, \"standard_deviation\": \"NaN\"},\n",
    "        \"f1-weighted\": {\"value\": f1_score_restricted, \"standard_deviation\": \"NaN\"},\n",
    "        \"novelty_ratio\": {\"value\": novelty_ratio, \"standard_deviation\": \"NaN\"}\n",
    "    }\n",
    "}\n",
    "with open(file_path, \"w\") as f:\n",
    "    json.dump(report_dict, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d5f80d8-06be-49c8-b487-4867b557ff34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# upload all results to S3\n",
    "s3_client = boto3.client(\"s3\")\n",
    "s3_client.upload_file(f'{results_dir}/pred_labels.txt', bucket_name, f\"{dev_split}/test/{year_month_test}/evaluation/pred_labels.txt\")\n",
    "s3_client.upload_file(f'{results_dir}/pred_probs.txt', bucket_name, f\"{dev_split}/test/{year_month_test}/evaluation/pred_probs.txt\")\n",
    "s3_client.upload_file(f'{results_dir}/pred_probs_softmax.txt', bucket_name, f\"{dev_split}/test/{year_month_test}/evaluation/pred_probs_softmax.txt\")\n",
    "s3_client.upload_file(f'{results_dir}/multiclass_metrics.json', bucket_name, f\"{dev_split}/test/{year_month_test}/evaluation/multiclass_metrics.json\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef000585-09d9-441c-9812-972f3b94c19b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess all new images from input CSV (with S3 loc), perform preprocessing including temporal feature engineering\n",
    "bucket_name = \"aai-590-tmp2\"\n",
    "dev_split = \"data_split\"\n",
    "\n",
    "# define a function that does all of the above given the year-month\n",
    "def evaluate_year_month(year_month = \"2012-03\", time_features = True):\n",
    "    print(f\"\\n=================MODEL INFERENCE===========================\")\n",
    "    print(f\"YEAR-MONTH: {year_month}\")\n",
    "    # Evaluate on specified month after training\n",
    "    year_month_test = year_month\n",
    "    s3_newdata_set =  f's3://{bucket_name}/{dev_split}/test/{year_month_test}/new_dataset.csv'\n",
    "    \n",
    "    new_dataset = []\n",
    "    new_dataset = S3ImageWithTimeFeatureDataset(s3_newdata_set)\n",
    "    print(f\"Total Number of images: {len(new_dataset)}\")\n",
    "    \n",
    "    new_dataset_loader = []\n",
    "    new_dataset_loader = DataLoader(new_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    print(f\"Number of batches: {len(new_dataset_loader)}\")\n",
    "\n",
    "   \n",
    "\n",
    "    pred_labels = []\n",
    "    pred_probs = []\n",
    "    batch_id = 0\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    #for image:\n",
    "    #for batch_id in range(len(new_dataset_loader)):\n",
    "        for images_batch, features_batch, scalars_batch in new_dataset_loader:\n",
    "            images, features = images_batch.to(device), features_batch.to(device)\n",
    "            if(time_features == True):\n",
    "                outputs = model(images, features)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            \n",
    "            pred_labels_batch = [idx2label[int(idx)] for idx in predicted]\n",
    "        \n",
    "            if (batch_id%32 == 0): \n",
    "                end_time = time.time()\n",
    "                elapsed_time = end_time - start_time\n",
    "                print(f\"batch_id: {batch_id}\")\n",
    "                #print(f\"outputs: {outputs}\")\n",
    "                #print(f\"pred_label: {pred_labels_batch}\")\n",
    "                print(f\"Elapsed time: {elapsed_time:.4f} seconds\")\n",
    "                start_time = time.time()\n",
    "        \n",
    "            batch_id += 1\n",
    "            pred_labels.extend(pred_labels_batch)\n",
    "            pred_probs.extend(outputs)\n",
    "\n",
    "    new_data_csv = pd.read_csv(s3_newdata_set)\n",
    "    true_labels = new_data_csv['label'].tolist()\n",
    "    \n",
    "    #restricted_indices = new_data_csv.index[new_data_csv['label'].isin(list(json_data.keys()))].tolist()\n",
    "    restricted_indices = new_data_csv.index[new_data_csv['label'].isin(label2idx.index.to_list())].tolist()\n",
    "    restricted_true_labels = [true_labels[i] for i in restricted_indices]\n",
    "    restricted_pred_labels = [pred_labels[i] for i in restricted_indices]\n",
    "    \n",
    "    class_report = classification_report(restricted_true_labels, restricted_pred_labels)\n",
    "    print(class_report)\n",
    "\n",
    "    accuracy_restricted = accuracy_score(restricted_true_labels, restricted_pred_labels)\n",
    "    f1_score_restricted = f1_score(restricted_true_labels, restricted_pred_labels, average='weighted')\n",
    "\n",
    "    # output: tensor from your model (after ReLU Linear)\n",
    "    pred_probs_linear = torch.stack(pred_probs)\n",
    "    pred_probs_softmax = F.softmax(pred_probs_linear, dim=1)  # dim=1 for batch x classes\n",
    "\n",
    "    #torch.set_printoptions(precision=2, sci_mode=False)\n",
    "    #print(\"pred_probs\")\n",
    "    #print(pred_probs)\n",
    "    #print(\"\\npred_probs_linear\")\n",
    "    #print(pred_probs_linear)\n",
    "    #print(\"\\npred_probs_softmax\")\n",
    "    #print(pred_probs_softmax)\n",
    "    \n",
    "    \n",
    "\n",
    "    # NOVELTY RATIO\n",
    "    threshold = 0.7  # Example threshold for MSP\n",
    "    is_novel = (pred_probs_softmax.max(dim=1)[0] < threshold).sum()\n",
    "    novelty_ratio = is_novel/len(pred_probs_softmax)\n",
    "    novelty_ratio = novelty_ratio.item()\n",
    "    novelty_ratio\n",
    "\n",
    "    # Save to local files\n",
    "    results_dir = f'{dev_split}/custom_model_results/'\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    file_name = 'pred_labels.txt'\n",
    "    file_path = os.path.join(results_dir, file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in pred_labels:\n",
    "            f.write(f\"{item}\\n\")\n",
    "            \n",
    "    file_name = 'pred_probs.txt'\n",
    "    file_path = os.path.join(results_dir, file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in pred_probs:\n",
    "            f.write(f\"{item}\\n\")\n",
    "    \n",
    "    file_name = 'pred_probs_softmax.txt'\n",
    "    file_path = os.path.join(results_dir, file_name)\n",
    "    with open(file_path, 'w') as f:\n",
    "        for item in pred_probs_softmax:\n",
    "            f.write(f\"{item}\\n\")\n",
    "\n",
    "    file_name = 'multiclass_metrics.json'\n",
    "    file_path = os.path.join(results_dir, file_name)\n",
    "    \n",
    "    report_dict = {\n",
    "        \"multiclass_classification_metrics\": {\n",
    "            \"accuracy\": {\"value\": accuracy_restricted, \"standard_deviation\": \"NaN\"},\n",
    "            \"f1-weighted\": {\"value\": f1_score_restricted, \"standard_deviation\": \"NaN\"},\n",
    "            \"novelty_ratio\": {\"value\": novelty_ratio, \"standard_deviation\": \"NaN\"}\n",
    "        }\n",
    "    }\n",
    "    print(json.dumps(report_dict, indent=2))\n",
    "    with open(file_path, \"w\") as f:\n",
    "        json.dump(report_dict, f)\n",
    "\n",
    "\n",
    "    # upload all results to S3\n",
    "    if(time_features==True):\n",
    "        eval_results = 'eval_results_WithTimeFeatures'\n",
    "    else:\n",
    "        eval_results = 'eval_results_NoTimeFeatures'\n",
    "    \n",
    "    s3_client = boto3.client(\"s3\")\n",
    "    s3_client.upload_file(f'{results_dir}/pred_labels.txt', bucket_name, f\"{dev_split}/test/{year_month_test}/{eval_results}/pred_labels.txt\")\n",
    "    s3_client.upload_file(f'{results_dir}/pred_probs.txt', bucket_name, f\"{dev_split}/test/{year_month_test}/{eval_results}/pred_probs.txt\")\n",
    "    s3_client.upload_file(f'{results_dir}/pred_probs_softmax.txt', bucket_name, f\"{dev_split}/test/{year_month_test}/{eval_results}/pred_probs_softmax.txt\")\n",
    "    s3_client.upload_file(f'{results_dir}/multiclass_metrics.json', bucket_name, f\"{dev_split}/test/{year_month_test}/{eval_results}/multiclass_metrics.json\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807efa96-00d6-49a8-96b9-70a8219f58ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_year_month(\"2013-04\", time_features=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b60740-b94b-486e-8098-590c9f6702d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "s3_test_csv = 's3://aai-590-tmp2/data_split/test/test-meta.csv'\n",
    "test_meta_df = pd.read_csv(s3_test_csv)\n",
    "test_meta_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13a740e-1f84-419d-a45b-e9389b40978c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df_year_months = test_meta_df['year_month'].unique().tolist()\n",
    "test_df_year_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4906295-91be-4d8b-891b-4168d7e5ab18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on all months\n",
    "#for year_month in [\"2013-04\", \"2012-04\", \"2012-05\", \"2012-06\", \"2012-07\", \"2012-08\", \"2012-09\", \"2012-10\", \"2012-11\", \"2012-12\"]:\n",
    "for year_month in test_df_year_months:\n",
    "    evaluate_year_month(year_month, time_features=False)\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e79ba8e-7802-448d-aeb9-0b21b653ee42",
   "metadata": {},
   "outputs": [],
   "source": [
    "year_month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9390bca-a518-480f-9ac1-1bb11f877dce",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
